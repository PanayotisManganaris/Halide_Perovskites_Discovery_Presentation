#+options: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline
#+options: author:t broken-links:nil c:nil creator:nil
#+options: d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t
#+options: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+options: timestamp:t title:t toc:t todo:t |:t
#+title: Statistical Learning for Halide Perovskite Discovery
#+date: \today{}
#+author: Panayotis Manganaris\inst{1}
#+email: pmangana@purdue.edu
#+language: en
#+select_tags: export
#+exclude_tags: noexport
#+creator: Emacs 29.0.50 (Org mode 9.5.3)
#+latex_header:\usepackage{listings}
#+latex_engraved-theme: t
#+setupfile: ~/org/mrg_beamer_header.org
#+include: ~/org/mrg_beamer_frontmatter.org
* AI Background
** Artificial Intelligence                                         :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:END:
*** The Four Approached to AI                                     :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:
| Thinking Humanly              | Thinking Rationally       |
| - Turing test approach        | - Laws of Thought         |
| (The Six Fields of AI)[fn:1]  | -- logical positing       |
| -- NLP                        | -- proven algorithms      |
| -- Knowledge Representation   | -- correct inference      |
| -- automated reasoning        | -- syllogistic reason     |
| -- Machine Learning           |                           |
| -- computer vision            |                           |
| -- robotics                   |                           |
|-------------------------------+---------------------------|
|-------------------------------+---------------------------|
| Acting Humanly                | Acting Rationally         |
| - cognitive modeling approach | - The rational agent      |
| -- neuromorphic algorithms    | -- inference + reflex     |
|                               | -- inference vs deduction |
** Machine Learning                                                :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:BEAMER_opt: allowframebreaks
:END:
*** ML Contributes to AI
- Adaptable *agent*
  - Contextual judgment of *percept* relevance
  - Autonomous utilization of *percept sequence*
- Learning
  - *function* performance improves with exposure to more percepts
*** Artifical Agency                                         :B_definition:
:PROPERTIES:
:BEAMER_env: definition
:END:
- agent :: self-contained sensor->function->action pipeline
- function :: Set of all possible responses for all possible percepts
- percept :: sensory input
- percept sequence :: history of sensory input
*** Supervised Training                                           :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:
Encourage the agent to behave "correctly"
1. Minimize Loss
2. Maximize Score
*** Unsupervised Training                                         :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:
The agent determines something principally true about its environment
using mathematical/logical characterization methods.
- find eigenvectors and eigenvalues
- differentially calculate optima
** Inverse Design                                                  :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:END:
*** A Type of AI Implementation                                   :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:
- senses :: maps points in many dimensions
- function :: reliably navigates it's environment searching for optima
- action :: returns its findings to human interpreters
* Chemistry Background
** Perovskite Structure and Chemistry                              :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:END:
Example[fn:3] of hybrid organic-inorganic MAPbI_3
#+attr_latex: :width 190
[[file:cubic_perovskite.png]]
** Our Dataset                                                     :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:END:
*** col                                                             :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.35
:END:
**** DFT Simulations                                             :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:
1. geometry optimization
2. Static band structure and optical absorption
**** Levels of Theory
- PBE
- HSE06
- PBE+HSE06(SOC)
- Experimental
*** col                                                             :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.65
:END:
| Formula            | bg_eV |  \eta | LoT |
|--------------------+-------+-------+-----|
| MAPbCl3            |  3.03 | 0.002 | EXP |
| CsPbI0.375Br2.625  |  1.68 | 0.153 | PBE |
| RbSnBr2.625Cl0.375 |  1.44 |   NaN | HSE |
| CsGeCl3            |  1.05 | 0.176 | PBE |
| MASr0.5Pb0.5Cl3    |  5.31 |   NaN | HSE |
| MABa0.25Pb0.75I3   |  1.99 | 0.015 | PBE |
| MASnI3             |  2.57 |   NaN | HSE |
| MACa0.5Pb0.5Cl3    |  5.32 |   NaN | HSE |
| ...                |   ... |   ... | ... |
** Band Gap Fidelity                                               :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:BEAMER_opt: allowframebreaks
:END:
#+CAPTION: PBE vs HSE Band Gaps
#+attr_latex: :width 250
[[file:pbe_v_hse_bg.png]]
Comparing computational with experimental[fn:2] band gaps
*** col                                                             :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.4
:END:
#+CAPTION: PBE vs Almora BG
#+attr_latex: :height 110
[[file:pbe_v_almora_bg.png]]
*** col                                                             :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+CAPTION: HSE vs Almora BG
#+attr_latex: :height 110
[[file:hse_v_almora_bg.png]]
* Pipeline
** Data Pre-Processing                                             :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:END:
#+begin_src ditaa :eval never-export :export results :file ./data_proc.png
  +------------+      +------------+         +------------+
  |            |      |            |         |            +-----+
  |  cleaning  +----->|  grouping  +-------->|  labeling  |     |
  |            |      |            |         |            |<-+  |
  +------------+      +------------+         +------------+  |  |
  +---------+        +--------------+      +--------------+  |  |
  |         |        |              |      |              +--+  |
  |  {X,y}  |<-------+  validating  |<-----+ featurizing  |     |
  |         |        |              |      |              |<----+
  +---------+        +--------------+      +--------------+
#+end_src

#+CAPTION: Data Preprocessing Workflow to Implement with Python Pandas
#+attr_latex: :width 300
[[file:./data_proc.png]]

** Machine Learning Pipeline                                       :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:END:
#+begin_src ditaa :eval never-export :export results :file ./ML_pipe.png
           +-------------------+
           |                   |
     Test  |  Make Test/Train  |
  +--------+       Split       |
  |        |                   |
  |        +-------+-----------+
  |                |
  |       ---------+------------------------------------------------------
  |      |         |Train         --------------------------------------  |
  |      |         v             |                                      | |
  |      | +-------------------+ | +---------+    +-------------------+ | |
  |      | |                   | | |         |    |                   | | |
  |      | |  Make Validation  | | |  score  +--->|  Define Pipeline  | | |
  |      | |       Folds       | | |         |    |                   | | |
  |      | |                   | | +----+----+    |                   | | |
  |      | +-------+-----------+ |      ^         +------------+------+ | |
  |      |         |             |      |                      |        | |
  |      |         |             |  +---+--------------+       |        | |
  |      |         |             |  |                  |       |        | |
  |      |         +-------------+->|   fit pipeline   |<------+        | |
  |      |                       |  |                  |                | |
  |      |                       |  +----+-------------+                | |
  |      |                       |       |                     HPO Loop | |
  |      |                        -------+------------------------------  |
  |      | Performance Targeting         |                                |
  |       -------------------------------+--------------------------------
  |                                      |
  |                                      v
  |                        +----------------+
  +----------------------->| test pipeline  |
                           +----------------+
#+end_src

#+CAPTION: Machine Learning Pipeline to Implement with Python SciKit-Learn
#+attr_latex: :width 300
[[file:./ML_pipe.png]]

** Implementation in Jupyter Python                                :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:BEAMER_opt: allowframebreaks
:END:
#+latex: \small
#+begin_src python :export code :eval never-export :tangle ./pretty_pipeline.py
  import sys, os
  sys.path.append(os.path.expanduser("~/src/cmcl"))
  sys.path.append(os.path.expanduser("~/src/spyglass"))
  import pandas as pd
  import numpy as np
  import cmcl
  from spyglass.model_imaging import parityplot
  from sklearn.pipeline import make_pipeline
  from sklearn.compose import ColumnTransformer
  from sklearn.<module> import NumPreProcessor1
  from sklearn.<module> import CatPreProcessor1
  from sklearn.<module> import NumPreProcessor2
  from sklearn.<module> import CatPreProcessor2
  from sklearn.<module> import Estimator

  df = pd.read_<data>('./file.<data>')
  df = df.groupby('Formula', as_index=False).agg(
      {'bg_eV':'median', 'efficiency':'median'})

  dc = df.ft.comp()
  dc = dc.assign(label='label')

  numeric_features = dc
  .select_dtypes(np.number)
  .columns
  .to_list()
  numeric_pipeline = make_pipeline(NumPreProcessor1(),
                                   NumPreProcessor2())
  categorical_features = mc
  .select_dtypes('object')
  .columns
  .to_list()
  catagorical_pipeline = make_pipeline(CatPreProcessor1(),
                                       CatPreProcessor2())


  preprocessor = ColumnTransformer(
      transformers=[
          ("num", numeric_pipeline, numeric_features),
          ("cat", categorical_pipline, categorical_features),
      ]
  )

  ss = ShuffleSplit(n_splits=1, train_size=0.8,
                    random_state=None)
  train_idx, test_idx = next(ss.split(dc))
  dc_tr, dc_ts = dc.iloc[train_idx], dc.iloc[test_idx]
  df_tr, df_ts = df.iloc[train_idx], df.iloc[test_idx]

  pipe = make_pipeline(preprocessor, Estimator())

  pipe.fit(dc_tr, df_tr.<target>)


  p, data = parityplot(pipe,
                       dc_ts, df_ts.<target>.to_frame(),
                       aspect=1.0)
  p.figure.show()
#+end_src

* Feature Engineering
** PCA                                                             :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:END:
*** col                                                             :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.75
:END:
#+CAPTION: Learn transformation matrix \(U\) to diagonalizes the matrix \(A\).
#+CAPTION: The Principal Components in \(Q\) corresponding to the largest
#+CAPTION: two Singular Values in \(S\) contain the majority of
#+CAPTION: the variance in the data.
#+attr_latex: :width 200
[[file:comp_ratio_projection.png]]
*** col                                                             :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.25
:END:
\[
UAU^\dag = Q^{-1}SQ
\]
** tSNE                                                            :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:END:
#+CAPTION: Learn a low-dimensional (2 or 3D) embedding space
#+CAPTION: in which statistical similarity governs
#+CAPTION: the proximity of high-dimensional data points
#+attr_latex: :width 200
[[file:tsne_comp_DecoE_clusters.png]]
** UMAP                                                            :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:END:
#+CAPTION: Learn a manifold embedding space in which nearest
#+CAPTION: neighbors form clusters
#+attr_latex: :width 200
file:umap_projection.png
* Supervised Architectures
** Linear regressions on BG                                        :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:BEAMER_opt: allowframebreaks
:END:
#+CAPTION: OLS determines \(\vec{w}\) so that
#+CAPTION: \(f(x) = \vec{x}^T\vec{w}\), \(y_i = f(x_i) + \epsilon_i\) and
#+CAPTION: all \epsilon_i are as small as possible
#+attr_latex: :width 185
[[file:linear_bg_c.png]]

#+CAPTION: elasticnet determines \(\vec{w}\) as before, but also works
#+CAPTION: to sparsify the model
#+attr_latex: :width 185
[[file:elastic_bg_c.png]]
** OLS weights                                                     :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:END:
*** col                                                             :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.7
:END:
| site | element |            |
|------+---------+------------|
| A    | Cs      |  23.771206 |
| A    | FA      |  25.794831 |
| A    | K       |  22.774475 |
| A    | MA      |  25.452629 |
| A    | Rb      |  23.282988 |
| B    | Ba      | -32.603053 |
| B    | Ca      | -31.378385 |
| B    | Ge      | -45.001044 |
| B    | Pb      | -42.526511 |
| B    | Sn      | -46.868114 |
| B    | Sr      | -32.068490 |
| X    | Br      |   0.939374 |
| X    | Cl      |   1.769032 |
| X    | I       |   0.140658 |
.
*** col                                                             :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.3
:END:
|   |       RSS |
|---+-----------|
| A | 54.213044 |
| B | 95.426246 |
| X |  2.007905 |

** elasticnet weights                                              :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:END:
*** col                                                             :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.7
:END:
| site | element |           |
|------+---------+-----------|
| A    | Cs      | -0.191057 |
| A    | FA      |  1.589015 |
| A    | K       | -1.081903 |
| A    | MA      |  1.214167 |
| A    | Rb      | -0.530437 |
| B    | Ba      |  5.139688 |
| B    | Ca      |  6.424156 |
| B    | Ge      | -5.879154 |
| B    | Pb      | -3.673012 |
| B    | Sn      | -7.689152 |
| B    | Sr      |  5.678253 |
| X    | Br      |  0.000000 |
| X    | Cl      |  0.819669 |
| X    | I       | -0.786942 |
*** col                                                             :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.3
:END:
|   |       RSS |
|---+-----------+
| A |  2.342552 |
| B | 14.391222 |
| X |  1.136281 |

** COMMENT Decision Tree on BG                                     :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:END:

** Random Forest Regression on BG                                  :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:BEAMER_opt: allowframebreaks
:END:
#+CAPTION: RFR initializes an ensemble of Decision Trees and
#+CAPTION: averages their results to return its prediction.
#+CAPTION: This leverages the DT's ability to strongly bias
#+CAPTION: itself to the data and relies on randomness to
#+CAPTION: explain variance in the underlying process
#+attr_latex: :width 170
file:rfr_c_bg.png
** COMMENT SISSO
*** Analogy to Non-Dimensional Analysis
** Gaussian Process or BG                                          :B_frame:
:PROPERTIES:
:BEAMER_env: frame
:BEAMER_opt: allowframebreaks
:END:
#+CAPTION: GPR picks functions from a distribution derived from the data
#+CAPTION: covariance. The functions that satisfy the data form the fit.
#+attr_latex: :width 185
[[file:gpr_bg_c.png]]
*** Regularization with Priors                                    :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:
- Conditional Probablity :: \(P(x|y) = \frac{P(x)P(y|x)}{P(x)}\)
- Conditional Odds :: \(O(x|y) = O(x)\frac{P(x|y)}{P(x|\neg{}y)}\)
- Isolated Bayesian Prior :: \(B = \frac{P(x|y)}{P(x|\neg{}y)}\)

** COMMENT Support Vector Machine
** COMMENT Boltzmann Machines
** COMMENT Artificial Neural Network
* 
[[printbibliography:]]
* Footnotes
[fn:1][[cite:&russell-2010-artif]]
[fn:2][[cite:&almora-2020-devic-perfor]]
[fn:3][[cite:&mannodi-kanakkithodi-2022-data-driven]]
